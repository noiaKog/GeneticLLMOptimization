{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoQA2Xh88GMg"
      },
      "source": [
        "# Installs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9CvYOlQ8RjX"
      },
      "outputs": [],
      "source": [
        "!pip install transformers --q\n",
        "!pip install torch --q\n",
        "!pip install einops --q\n",
        "!pip install biopython --q"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FfIwAoaa8L4E"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R065s4sd77Uh",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from Bio import SeqIO\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch.utils.data import random_split\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import defaultdict\n",
        "import pickle\n",
        "from transformers import TFBertForSequenceClassification\n",
        "from transformers import OpenAIGPTConfig, OpenAIGPTModel\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE, Unigram, WordLevel, WordPiece\n",
        "from tokenizers.trainers import BpeTrainer, WordLevelTrainer,WordPieceTrainer, UnigramTrainer\n",
        "from tokenizers.pre_tokenizers import Sequence, Digits, Whitespace\n",
        "from transformers import PreTrainedTokenizerFast\n",
        "import random\n",
        "from tokenizers import Tokenizer, models, trainers\n",
        "from transformers import BertConfig, BertForSequenceClassification, DataCollatorForLanguageModeling, Trainer, TrainingArguments\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from transformers import AutoTokenizer, BertForMaskedLM\n",
        "import pandas as pd\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertConfig, BertForMaskedLM\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel , RobertaTokenizer, TFRobertaModel , AutoTokenizer, AutoModel\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from transformers import RobertaForMaskedLM, RobertaTokenizer, RobertaTokenizerFast, RobertaConfig\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
        "from transformers import RobertaForSequenceClassification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3EUqzsOz8iO7"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Awh61keh5S1"
      },
      "source": [
        "# Data for Tokenizer and Masking model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Em_CiUXKe4Dq"
      },
      "outputs": [],
      "source": [
        "all_data_pos = pd.read_csv('data/all_data_combined_df.csv', index_col = False)\n",
        "all_data_pos['True_label']=1\n",
        "\n",
        "train_df, validation_df = train_test_split(all_data_pos, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KUOMuaFOyv5"
      },
      "outputs": [],
      "source": [
        "#this will be used for training the tokenizers\n",
        "df_sequences = all_data_pos['seq'].tolist()\n",
        "df_labels = all_data_pos['True_label'].tolist()\n",
        "\n",
        "#this will be used for the pre-train(masking)\n",
        "df_train_sequences = train_df['seq'].tolist()\n",
        "df_train_labels = train_df['True_label'].tolist()\n",
        "\n",
        "df_val_sequences = validation_df['seq'].tolist()\n",
        "df_val_labels = validation_df['True_label'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kTVkBKaq6XO"
      },
      "source": [
        "# Tokenizer BPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3oQv4FV7pf1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class DNADataset(Dataset):\n",
        "    def __init__(self, sequences, tokenizer, max_length=6):\n",
        "        self.sequences = sequences\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            sequence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove batch dimension\n",
        "        inputs['labels'] = inputs['input_ids'].clone()\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75OEFWpQ8XaF",
        "outputId": "3178c0fe-02f8-4b17-a056-6f983d67c595"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import RobertaForMaskedLM, RobertaTokenizer, RobertaTokenizerFast, RobertaConfig\n",
        "from tokenizers import Tokenizer, models, pre_tokenizers, decoders, trainers, processors\n",
        "\n",
        "# Initialize a blank RoBERTa tokenizer\n",
        "tokenizer = Tokenizer(models.BPE())\n",
        "\n",
        "# Define pre-tokenizer\n",
        "tokenizer.pre_tokenizer = pre_tokenizers.ByteLevel()\n",
        "\n",
        "# Define decoder\n",
        "tokenizer.decoder = decoders.ByteLevel()\n",
        "\n",
        "# Define the trainer\n",
        "trainer = trainers.BpeTrainer(\n",
        "    # vocab_size=5000,  # Define the vocab size\n",
        "    special_tokens=[\"<s>\", \"<pad>\", \"</s>\", \"<unk>\", \"<mask>\"] #, max_token_length=7\n",
        ")\n",
        "\n",
        "# Train the tokenizer\n",
        "tokenizer.train_from_iterator(df_sequences, trainer=trainer)\n",
        "\n",
        "# Enable post-processing to add special tokens\n",
        "tokenizer.post_processor = processors.ByteLevel(trim_offsets=False)\n",
        "\n",
        "# Wrap the tokenizer in the RobertaTokenizerFast class\n",
        "roberta_tokenizer = RobertaTokenizerFast(tokenizer_object=tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjzjRNnUXEhu",
        "outputId": "5bf64d73-4394-495c-dbdd-59814f5156f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('models/bpe/bpe_tokenizer_rep/tokenizer_config.json',\n",
              " 'models/bpe/bpe_tokenizer_rep/special_tokens_map.json',\n",
              " 'models/bpe/bpe_tokenizer_rep/vocab.json',\n",
              " 'models/bpe/bpe_tokenizer_rep/merges.txt',\n",
              " 'models/bpe/bpe_tokenizer_rep/added_tokens.json')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "roberta_tokenizer.save_pretrained(\"models/bpe/bpe_tokenizer_rep\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDh8ZilvzwFS"
      },
      "source": [
        "# Masking Model - BPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpHI1yaokBWI"
      },
      "outputs": [],
      "source": [
        "roberta_tokenizer = RobertaTokenizer.from_pretrained(\"models/bpe/bpe_tokenizer_rep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aCDBfWsakBWL",
        "outputId": "2f8e4327-8e41-44f8-c274-024db9fe08f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 30000\n",
            "Minimum token length: 1\n",
            "Average token length: 8.32\n",
            "Maximum token length: 128\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "# Path to the vocabulary JSON file\n",
        "vocab_file = \"models/bpe/bpe_tokenizer_rep/vocab.json\"\n",
        "\n",
        "# Load the vocabulary JSON file\n",
        "with open(vocab_file, 'r') as f:\n",
        "    vocab = json.load(f)\n",
        "\n",
        "# Calculate statistics\n",
        "token_lengths = [len(token) for token in vocab.keys()]\n",
        "min_len = min(token_lengths)\n",
        "avg_len = sum(token_lengths) / len(token_lengths)\n",
        "max_len = max(token_lengths)\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Print statistics\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "print(f\"Minimum token length: {min_len}\")\n",
        "print(f\"Average token length: {avg_len:.2f}\")\n",
        "print(f\"Maximum token length: {max_len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpDKiQ1R02Wj"
      },
      "source": [
        "Model configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTLbZgExZJUG"
      },
      "outputs": [],
      "source": [
        "# Define model configuration\n",
        "config = RobertaConfig(\n",
        "    vocab_size=roberta_tokenizer.vocab_size,\n",
        "    max_position_embeddings=514,\n",
        "    num_attention_heads=12,\n",
        "    num_hidden_layers=6,\n",
        "    type_vocab_size=1,\n",
        "    pad_token_id=roberta_tokenizer.pad_token_id,\n",
        "    bos_token_id=roberta_tokenizer.bos_token_id,\n",
        "    eos_token_id=roberta_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "# Initialize the model\n",
        "model = RobertaForMaskedLM(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8u5dAsRs0i7L"
      },
      "source": [
        "Dataloaders from positive data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H3n29_vEkBWM"
      },
      "outputs": [],
      "source": [
        "# Create a dataset object\n",
        "train_dataset = DNADataset(df_train_sequences, tokenizer = roberta_tokenizer)\n",
        "validation_dataset = DNADataset(df_val_sequences, tokenizer = roberta_tokenizer)\n",
        "\n",
        "# Create a dataloader\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "validation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dbcg06w906Vd"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAjOLD-4mAwe",
        "outputId": "044c1544-e272-447f-a2cd-cbeed59afb9b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/linago/.conda/envs/lina_env/lib/python3.11/site-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/2, Iteration 300, Training Loss: 6.3335\n",
            "Epoch 1/2, Iteration 600, Training Loss: 5.5724\n",
            "Epoch 1/2, Iteration 900, Training Loss: 4.9673\n",
            "Epoch 1/2, Iteration 1200, Training Loss: 4.4685\n",
            "Epoch 1/2, Iteration 1500, Training Loss: 4.0526\n",
            "Epoch 1/2, Iteration 1800, Training Loss: 3.7022\n",
            "Epoch 1/2, Iteration 2100, Training Loss: 3.4030\n",
            "Epoch 1/2, Iteration 2400, Training Loss: 3.1516\n",
            "Epoch 1/2, Iteration 2700, Training Loss: 2.9358\n",
            "Epoch 1/2, Iteration 3000, Training Loss: 2.7467\n",
            "Epoch 1/2, Iteration 3300, Training Loss: 2.5806\n",
            "Epoch 1/2, Iteration 3600, Training Loss: 2.4332\n",
            "Epoch 1/2, Iteration 3900, Training Loss: 2.3023\n",
            "Epoch 1/2, Iteration 4200, Training Loss: 2.1840\n",
            "Epoch 1/2, Iteration 4500, Training Loss: 2.0781\n",
            "Epoch 1/2, Iteration 4800, Training Loss: 1.9817\n",
            "Epoch 1/2, Iteration 5100, Training Loss: 1.8939\n",
            "Epoch 1/2, Iteration 5400, Training Loss: 1.8138\n",
            "Epoch 1/2, Iteration 5700, Training Loss: 1.7405\n",
            "Epoch 1/2, Iteration 6000, Training Loss: 1.6723\n",
            "Epoch 1/2, Iteration 6300, Training Loss: 1.6096\n",
            "Epoch 1/2, Iteration 6600, Training Loss: 1.5510\n",
            "Epoch 1/2, Iteration 6900, Training Loss: 1.4966\n",
            "Epoch 1/2, Iteration 7200, Training Loss: 1.4462\n",
            "Epoch 1/2, Iteration 7500, Training Loss: 1.3987\n",
            "Epoch 1/2, Iteration 7800, Training Loss: 1.3543\n",
            "Epoch 1/2, Iteration 8100, Training Loss: 1.3126\n",
            "Epoch 1/2, Iteration 8400, Training Loss: 1.2734\n",
            "Epoch 1/2, Iteration 8700, Training Loss: 1.2365\n",
            "Epoch 1/2, Iteration 9000, Training Loss: 1.2015\n",
            "Epoch 1/2, Iteration 9300, Training Loss: 1.1687\n",
            "Epoch 1/2, Iteration 9600, Training Loss: 1.1375\n",
            "Epoch 1/2, Iteration 9900, Training Loss: 1.1078\n",
            "Epoch 1/2, Iteration 10200, Training Loss: 1.0797\n",
            "Epoch 1/2, Iteration 10500, Training Loss: 1.0531\n",
            "Epoch 1/2, Iteration 10800, Training Loss: 1.0277\n",
            "Epoch 1/2, Iteration 11100, Training Loss: 1.0033\n",
            "Epoch 1/2, Iteration 11400, Training Loss: 0.9802\n",
            "Epoch 1/2, Training Loss: 0.9610\n",
            "Epoch 1/2, Validation Loss: 0.0398\n",
            "Epoch 2/2, Iteration 300, Training Loss: 0.0792\n",
            "Epoch 2/2, Iteration 600, Training Loss: 0.0760\n",
            "Epoch 2/2, Iteration 900, Training Loss: 0.0742\n",
            "Epoch 2/2, Iteration 1200, Training Loss: 0.0716\n",
            "Epoch 2/2, Iteration 1500, Training Loss: 0.0695\n",
            "Epoch 2/2, Iteration 1800, Training Loss: 0.0680\n",
            "Epoch 2/2, Iteration 2100, Training Loss: 0.0665\n",
            "Epoch 2/2, Iteration 2400, Training Loss: 0.0652\n",
            "Epoch 2/2, Iteration 2700, Training Loss: 0.0640\n",
            "Epoch 2/2, Iteration 3000, Training Loss: 0.0627\n",
            "Epoch 2/2, Iteration 3300, Training Loss: 0.0612\n",
            "Epoch 2/2, Iteration 3600, Training Loss: 0.0601\n",
            "Epoch 2/2, Iteration 3900, Training Loss: 0.0588\n",
            "Epoch 2/2, Iteration 4200, Training Loss: 0.0576\n",
            "Epoch 2/2, Iteration 4500, Training Loss: 0.0565\n",
            "Epoch 2/2, Iteration 4800, Training Loss: 0.0554\n",
            "Epoch 2/2, Iteration 5100, Training Loss: 0.0542\n",
            "Epoch 2/2, Iteration 5400, Training Loss: 0.0533\n",
            "Epoch 2/2, Iteration 5700, Training Loss: 0.0521\n",
            "Epoch 2/2, Iteration 6000, Training Loss: 0.0512\n",
            "Epoch 2/2, Iteration 6300, Training Loss: 0.0503\n",
            "Epoch 2/2, Iteration 6600, Training Loss: 0.0494\n",
            "Epoch 2/2, Iteration 6900, Training Loss: 0.0485\n",
            "Epoch 2/2, Iteration 7200, Training Loss: 0.0476\n",
            "Epoch 2/2, Iteration 7500, Training Loss: 0.0467\n",
            "Epoch 2/2, Iteration 7800, Training Loss: 0.0460\n",
            "Epoch 2/2, Iteration 8100, Training Loss: 0.0452\n",
            "Epoch 2/2, Iteration 8400, Training Loss: 0.0445\n",
            "Epoch 2/2, Iteration 8700, Training Loss: 0.0438\n",
            "Epoch 2/2, Iteration 9000, Training Loss: 0.0431\n",
            "Epoch 2/2, Iteration 9300, Training Loss: 0.0424\n",
            "Epoch 2/2, Iteration 9600, Training Loss: 0.0418\n",
            "Epoch 2/2, Iteration 9900, Training Loss: 0.0412\n",
            "Epoch 2/2, Iteration 10200, Training Loss: 0.0405\n",
            "Epoch 2/2, Iteration 10500, Training Loss: 0.0399\n",
            "Epoch 2/2, Iteration 10800, Training Loss: 0.0394\n",
            "Epoch 2/2, Iteration 11100, Training Loss: 0.0388\n",
            "Epoch 2/2, Iteration 11400, Training Loss: 0.0383\n",
            "Epoch 2/2, Training Loss: 0.0378\n",
            "Epoch 2/2, Validation Loss: 0.0110\n"
          ]
        }
      ],
      "source": [
        "from transformers import AdamW\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define training parameters\n",
        "num_epochs = 2\n",
        "learning_rate = 1e-5\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "train_history=[]\n",
        "val_history=[]\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for i, batch in enumerate(train_dataloader):\n",
        "        inputs = {key: val.to(model.device) for key, val in batch.items()}\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs.loss\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        if i>0 and i % 300 ==0:\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Iteration {i}, Training Loss: {total_loss/i:.4f}\")\n",
        "\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    train_history.append(avg_loss)\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {avg_loss:.4f}\")\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        val_losses = []\n",
        "        for val_batch in validation_dataloader:\n",
        "            val_inputs = {key: val.to(model.device) for key, val in val_batch.items()}\n",
        "            val_outputs = model(**val_inputs)\n",
        "            val_loss = val_outputs.loss\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "        avg_val_loss = sum(val_losses) / len(val_losses)\n",
        "        val_history.append(avg_val_loss)\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Validation Loss: {avg_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sojRqruPkBWN"
      },
      "outputs": [],
      "source": [
        "# Save the model\n",
        "model.save_pretrained(\"models/bpe/bpe_masking_model_rep\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ttMZck1Gq6Xb"
      },
      "source": [
        "# Fine Tune BPE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aF7BNNNQkBWP"
      },
      "outputs": [],
      "source": [
        "results_dict = defaultdict(dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KB4iP6J00-WF"
      },
      "source": [
        "Data for finetuning - **Substitution**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LPDDW2GtkBWP"
      },
      "outputs": [],
      "source": [
        "train_tata = pd.read_csv(\"data_exp1/train_tata_met_2.csv\", index_col = False)\n",
        "val_tata = pd.read_csv(\"data_exp1/val_tata_met_2.csv\", index_col = False)\n",
        "test_tata = pd.read_csv('data_exp1/test_tata_met_2.csv', index_col = False)\n",
        "\n",
        "train_non_tata = pd.read_csv('data_exp1/train_non_tata_met_2.csv', index_col = False)\n",
        "val_non_tata = pd.read_csv('data_exp1/val_non_tata_met_2.csv', index_col = False)\n",
        "test_non_tata = pd.read_csv('data_exp1/test_non_tata_met_2.csv', index_col = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm6o_g9ckBWQ"
      },
      "outputs": [],
      "source": [
        "train = pd.concat([train_tata, train_non_tata])\n",
        "val = pd.concat([val_tata, val_non_tata])\n",
        "test = pd.concat([test_tata, test_non_tata])\n",
        "test.reset_index(drop=True, inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data for finetuning - **Genome**"
      ],
      "metadata": {
        "id": "n6xdd5jx8kQ3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train = pd.read_csv(\"/content/drive/MyDrive/פרויקט גמר/DATA/train and test/exp2 - genome - new train, val, test combined/train_exp2.csv\", index_col = False)\n",
        "# val = pd.read_csv(\"/content/drive/MyDrive/פרויקט גמר/DATA/train and test/exp2 - genome - new train, val, test combined/val_exp2.csv\", index_col = False)\n",
        "# test_tata = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/train and test/exp2 - genome - new train, val, test combined/test_tata_exp2.csv', index_col = False)\n",
        "# test_non_tata = pd.read_csv('/content/drive/MyDrive/פרויקט גמר/DATA/train and test/exp2 - genome - new train, val, test combined/test_non_tata_exp2.csv', index_col = False)"
      ],
      "metadata": {
        "id": "Fk7I_Epj8jwA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdE4_4MF1OSs"
      },
      "source": [
        "Dataset class for Fine Tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIV2VRRArGoQ"
      },
      "outputs": [],
      "source": [
        "class DNAClassificationDataset(Dataset):\n",
        "    def __init__(self, sequences, labels, tokenizer, max_length=128):\n",
        "        \"\"\"\n",
        "        Initializes the DNAClassificationDataset instance.\n",
        "\n",
        "        Args:\n",
        "            sequences (list): List of DNA sequences to be tokenized.\n",
        "            labels (list): List of labels corresponding to each sequence.\n",
        "            tokenizer (PreTrainedTokenizer): Tokenizer from the Hugging Face library for tokenizing sequences.\n",
        "            max_length (int, optional): Maximum length of the tokenized sequences after padding. Default is 128.\n",
        "        \"\"\"\n",
        "        self.sequences = sequences\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of sequences in the dataset.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of sequences in the dataset.\n",
        "        \"\"\"\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves a tokenized and padded sequence along with its label at the specified index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of the sequence to retrieve.\n",
        "\n",
        "        Returns:\n",
        "            dict: Dictionary containing the tokenized and padded sequence, labels, and input IDs.\n",
        "        \"\"\"\n",
        "        sequence = self.sequences[idx]\n",
        "        label = self.labels[idx]\n",
        "        inputs = self.tokenizer(\n",
        "            sequence,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            max_length=self.max_length,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "        inputs = {key: val.squeeze(0) for key, val in inputs.items()}  # Remove batch dimension\n",
        "\n",
        "        # Ensure the label is an integer\n",
        "        inputs['labels'] = torch.tensor(int(label), dtype=torch.long)\n",
        "        return inputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xzewPD5_DDjL"
      },
      "outputs": [],
      "source": [
        "seq = test['seq'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RhJnjnOP1Tuc"
      },
      "source": [
        "BPE Classification Model class\n",
        "\n",
        "\n",
        "*   Inintialize\n",
        "*   Create dataloaders\n",
        "*   Train\n",
        "*   Test\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKIjwJPnkBWQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AdamW, RobertaForSequenceClassification\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, matthews_corrcoef\n",
        "import os\n",
        "\n",
        "\n",
        "class ClassificationModelBPE:\n",
        "        \"\"\"\n",
        "        Initializes the DNAClassificationDataset instance.\n",
        "\n",
        "        Args:\n",
        "            sequences (list): List of DNA sequences to be tokenized.\n",
        "            labels (list): List of labels corresponding to each sequence.\n",
        "            tokenizer (PreTrainedTokenizer): Tokenizer from the Hugging Face library for tokenizing sequences.\n",
        "            max_length (int, optional): Maximum length of the tokenized sequences after padding. Default is 128.\n",
        "        \"\"\"\n",
        "    def __init__(self, train_df, val_df, test_tata_df, test_non_tata_df, organism='human', b_size=8):\n",
        "        \"\"\"\n",
        "        Initializes the ClassificationModelBPE class.\n",
        "\n",
        "        Parameters:\n",
        "        train_df (DataFrame): Training data.\n",
        "        val_df (DataFrame): Validation data.\n",
        "        test_tata_df (DataFrame): Test data with TATA sequences.\n",
        "        test_non_tata_df (DataFrame): Test data with non-TATA sequences.\n",
        "        organism (str): Organism type (default is 'human').\n",
        "        b_size (int): Batch size for data loaders (default is 8).\n",
        "        \"\"\"\n",
        "        self.organism = organism\n",
        "        self.batch_size = b_size\n",
        "        self.dataframes = {\n",
        "            'train': train_df,\n",
        "            'val': val_df,\n",
        "            'test_tata': test_tata_df,\n",
        "            'test_non_tata': test_non_tata_df\n",
        "        }\n",
        "\n",
        "        self.tokenizer = RobertaTokenizerFast.from_pretrained(\"models/bpe/bpe_tokenizer_rep\")\n",
        "        self.masking_model = RobertaForMaskedLM.from_pretrained(\"models/bpe/bpe_masking_model_rep\")\n",
        "        self.create_model()\n",
        "\n",
        "        # Create dataloaders and set as attributes\n",
        "        dataloaders = self.create_dataloaders(batch_size=self.batch_size)\n",
        "        self.train_dataloader = dataloaders['train']\n",
        "        self.val_dataloader = dataloaders['val']\n",
        "        self.test_tata_dataloader = dataloaders['test_tata']\n",
        "        self.test_non_tata_dataloader = dataloaders['test_non_tata']\n",
        "\n",
        "    def filter_and_convert(self, df, organism):\n",
        "        \"\"\"\n",
        "        Filters the dataframe based on the organism and converts it to sequences and labels.\n",
        "\n",
        "        Parameters:\n",
        "        df (DataFrame): The dataframe to filter and convert.\n",
        "        organism (str): The organism to filter by.\n",
        "\n",
        "        Returns:\n",
        "        list: A list of sequences.\n",
        "        list: A list of labels.\n",
        "        \"\"\"\n",
        "        filtered_df = df[df['organism'] == organism]\n",
        "        seq_list = filtered_df['seq'].tolist()\n",
        "        label_list = filtered_df['True_label'].tolist()\n",
        "        return seq_list, label_list\n",
        "\n",
        "    def create_dataloaders(self, batch_size=16):\n",
        "        \"\"\"\n",
        "        Creates dataloaders for training, validation, and test sets.\n",
        "\n",
        "        Parameters:\n",
        "        batch_size (int): Batch size for data loaders (default is 16).\n",
        "\n",
        "        Returns:\n",
        "        dict: A dictionary containing the data loaders for train, val, test_tata, and test_non_tata.\n",
        "        \"\"\"\n",
        "        train_seq, train_labels = self.filter_and_convert(self.dataframes['train'], self.organism)\n",
        "        val_seq, val_labels = self.filter_and_convert(self.dataframes['val'], self.organism)\n",
        "        test_tata_seq, test_tata_labels = self.filter_and_convert(self.dataframes['test_tata'], self.organism)\n",
        "        test_non_tata_seq, test_non_tata_labels = self.filter_and_convert(self.dataframes['test_non_tata'], self.organism)\n",
        "\n",
        "        # Create the dataset and dataloader\n",
        "        train_dataset = DNAClassificationDataset(train_seq, train_labels, self.tokenizer)\n",
        "        train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        val_dataset = DNAClassificationDataset(val_seq, val_labels, self.tokenizer)\n",
        "        val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        test_tata_dataset = DNAClassificationDataset(test_tata_seq, test_tata_labels, self.tokenizer)\n",
        "        test_tata_dataloader = DataLoader(test_tata_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        test_non_tata_dataset = DNAClassificationDataset(test_non_tata_seq, test_non_tata_labels, self.tokenizer)\n",
        "        test_non_tata_dataloader = DataLoader(test_non_tata_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "        return {\n",
        "            'train': train_dataloader,\n",
        "            'val': val_dataloader,\n",
        "            'test_tata': test_tata_dataloader,\n",
        "            'test_non_tata': test_non_tata_dataloader\n",
        "        }\n",
        "\n",
        "    def create_test_dataloader(self, test_df, organism, batch_size=16):\n",
        "        \"\"\"\n",
        "        Creates dataloaders for test sets\n",
        "        \"\"\"\n",
        "        filtered_df = test_df[test_df['organism'] == organism]\n",
        "        seq_list = filtered_df['seq'].tolist()\n",
        "        label_list = filtered_df['True_label'].tolist()\n",
        "\n",
        "        test_dataset = DNAClassificationDataset(seq_list, label_list, self.tokenizer)\n",
        "        test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        return test_dataloader\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"\n",
        "        Creates and initializes the sequence classification model.\n",
        "        \"\"\"\n",
        "        # Define configuration for sequence classification\n",
        "        config = RobertaConfig.from_pretrained(\"models/bpe/bpe_masking_model_rep\")\n",
        "        config.num_labels = 2  # binary classification\n",
        "\n",
        "        # Initialize the sequence classification model\n",
        "        self.classification_model = RobertaForSequenceClassification(config)\n",
        "\n",
        "        # Copy the pre-trained weights from the masked language model\n",
        "        self.classification_model.roberta.load_state_dict(self.masking_model.roberta.state_dict())\n",
        "        # return classification_model\n",
        "\n",
        "    def train_model(self, num_epochs=60, base_lr=1e-5, patience=3):\n",
        "        \"\"\"\n",
        "        Trains the classification model.\n",
        "\n",
        "        Parameters:\n",
        "        num_epochs (int): Number of epochs to train (default is 60).\n",
        "        base_lr (float): Base learning rate (default is 1e-5).\n",
        "        patience (int): Patience for early stopping (default is 3).\n",
        "\n",
        "        Returns:\n",
        "        dict: Training history containing loss and accuracy.\n",
        "        dict: Validation history containing loss, accuracy, f1, auc, and mcc.\n",
        "        \"\"\"\n",
        "        train_dataloader = self.train_dataloader\n",
        "        val_dataloader = self.val_dataloader\n",
        "\n",
        "        optimizer = torch.optim.AdamW(self.classification_model.parameters(), lr=base_lr)\n",
        "        scheduler = MultiStepLR(optimizer, milestones=list(range(4,num_epochs+1,4)), gamma=0.75)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.classification_model.to(device)\n",
        "\n",
        "       # Initialize history dictionaries\n",
        "        train_history = {\n",
        "            'loss': [],\n",
        "            'accuracy': []\n",
        "        }\n",
        "        val_history = {\n",
        "            'loss': [],\n",
        "            'accuracy': [],\n",
        "            'f1': [],\n",
        "            'auc': [],\n",
        "            'mcc': []\n",
        "        }\n",
        "\n",
        "        # Initialize early stopping criteria\n",
        "        best_val_accuracy = 0.0\n",
        "        epochs_without_improvement = 0\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            # Training phase\n",
        "            self.classification_model.train()\n",
        "            total_train_loss = 0\n",
        "            correct_train_predictions = 0\n",
        "            total_train_predictions = 0\n",
        "\n",
        "            for batch in train_dataloader:\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self.classification_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Calculate training accuracy\n",
        "                total_train_loss += loss.item()\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                correct_train_predictions += torch.sum(preds == labels).item()\n",
        "                total_train_predictions += labels.size(0)\n",
        "\n",
        "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "            train_accuracy = correct_train_predictions / total_train_predictions\n",
        "            train_history['loss'].append(avg_train_loss)\n",
        "            train_history['accuracy'].append(train_accuracy)\n",
        "\n",
        "            # Validation phase\n",
        "            self.classification_model.eval()\n",
        "            total_val_loss = 0\n",
        "            correct_val_predictions = 0\n",
        "            total_val_predictions = 0\n",
        "\n",
        "            all_labels = []\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch in val_dataloader:\n",
        "                    input_ids = batch['input_ids'].to(device)\n",
        "                    attention_mask = batch['attention_mask'].to(device)\n",
        "                    labels = batch['labels'].to(device)\n",
        "\n",
        "                    outputs = self.classification_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                    loss = outputs.loss\n",
        "                    logits = outputs.logits\n",
        "\n",
        "                    # Calculate validation accuracy\n",
        "                    total_val_loss += loss.item()\n",
        "                    preds = torch.argmax(logits, dim=1)\n",
        "                    probs = torch.softmax(logits, dim=1)[:, 1]\n",
        "\n",
        "                    correct_val_predictions += torch.sum(preds == labels).item()\n",
        "                    total_val_predictions += labels.size(0)\n",
        "\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_preds.extend(preds.cpu().numpy())\n",
        "                    all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "            avg_val_loss = total_val_loss / len(val_dataloader)\n",
        "            val_accuracy = correct_val_predictions / total_val_predictions\n",
        "            val_f1 = f1_score(all_labels, all_preds)\n",
        "            val_auc = roc_auc_score(all_labels, all_probs)\n",
        "            val_mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "            val_history['loss'].append(avg_val_loss)\n",
        "            val_history['accuracy'].append(val_accuracy)\n",
        "            val_history['f1'].append(val_f1)\n",
        "            val_history['auc'].append(val_auc)\n",
        "            val_history['mcc'].append(val_mcc)\n",
        "\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "            # Check early stopping criteria\n",
        "            if val_accuracy > best_val_accuracy:\n",
        "                best_val_accuracy = val_accuracy\n",
        "                epochs_without_improvement = 0\n",
        "            else:\n",
        "                epochs_without_improvement += 1\n",
        "                if epochs_without_improvement >= patience:\n",
        "                    print(\"Early stopping triggered\")\n",
        "                    break\n",
        "\n",
        "        # Save the trained classification model\n",
        "        self.classification_model.save_pretrained(f\"models/bpe/bpe fine tune models/rep/bpe_cls_{self.organism}_model_b{self.batch_size}\")\n",
        "        return train_history, val_history\n",
        "\n",
        "    def test_model(self, wrong_idx_dict, tata_flag):\n",
        "        \"\"\"\n",
        "        Tests the classification model on the test set.\n",
        "\n",
        "        Parameters:\n",
        "        tata_flag (str): Flag to indicate which test set to use ('tata', 'non_tata', 'all_data').\n",
        "\n",
        "        Returns:\n",
        "        dict: Test metrics containing loss, accuracy, f1, auc, and mcc.\n",
        "        \"\"\"\n",
        "        if tata_flag == 'tata':\n",
        "            test_dataloader = self.test_tata_dataloader\n",
        "        elif tata_flag == 'non_tata':\n",
        "            test_dataloader = self.test_non_tata_dataloader\n",
        "        elif tata_flag == 'combined':\n",
        "            print(organism)\n",
        "            test_dataloader = self.create_test_dataloader(test_df=test, organism=organism, batch_size=16)\n",
        "\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.classification_model.to(device)\n",
        "        self.classification_model.eval()\n",
        "\n",
        "        total_test_loss = 0\n",
        "        correct_test_predictions = 0\n",
        "        total_test_predictions = 0\n",
        "\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        all_probs = []\n",
        "        all_indices = []\n",
        "        incorrect_indices = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, batch in enumerate(test_dataloader):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = self.classification_model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                total_test_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(logits, dim=1)\n",
        "                probs = torch.softmax(logits, dim=1)[:, 1]\n",
        "\n",
        "                correct_test_predictions += torch.sum(preds == labels).item()\n",
        "                total_test_predictions += labels.size(0)\n",
        "\n",
        "                batch_indices = list(range(batch_idx * self.batch_size, batch_idx * self.batch_size + labels.size(0)))\n",
        "                # print(batch_indices)\n",
        "                all_indices.extend(batch_indices)\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "                incorrect_batch_indices = [i for i, (pred, label) in zip(batch_indices, zip(preds.cpu().numpy(), labels.cpu().numpy())) if pred != label]\n",
        "                # print(\"B:\", incorrect_batch_indices)\n",
        "                incorrect_indices.extend(incorrect_batch_indices)\n",
        "\n",
        "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
        "        test_accuracy = correct_test_predictions / total_test_predictions\n",
        "        test_f1 = f1_score(all_labels, all_preds)\n",
        "        test_auc = roc_auc_score(all_labels, all_probs)\n",
        "        test_mcc = matthews_corrcoef(all_labels, all_preds)\n",
        "\n",
        "        # Calculate confusion matrix\n",
        "        tn, fp, fn, tp = confusion_matrix(all_labels, all_preds).ravel()\n",
        "        tp_rate = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "        fp_rate = fp / (fp + tn) if (fp + tn) > 0 else 0\n",
        "        precision = precision_score(all_labels, all_preds)\n",
        "        recall = recall_score(all_labels, all_preds)\n",
        "        print(tata_flag)\n",
        "        print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
        "        print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
        "        print(f\"Test F1 Score: {test_f1:.4f}\")\n",
        "        print(f\"Test AUC: {test_auc:.4f}\")\n",
        "        print(f\"Test MCC: {test_mcc:.4f}\")\n",
        "        print(f\"True Positive Rate: {tp_rate:.4f}\")\n",
        "        print(f\"False Positive Rate: {fp_rate:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"True Positives (TP): {tp}\")\n",
        "        print(f\"False Positives (FP): {fp}\")\n",
        "        print(f\"True Negatives (TN): {tn}\")\n",
        "        print(f\"False Negatives (FN): {fn}\")\n",
        "        wrong_idx_dict[f'{self.organism}_{tata_flag}'] = incorrect_indices\n",
        "        wrong_idx_dict = {str(key): value for key, value in wrong_idx_dict.items()}\n",
        "\n",
        "        print()\n",
        "\n",
        "        test_metrics = {\n",
        "            'loss': avg_test_loss,\n",
        "            'accuracy': test_accuracy,\n",
        "            'f1': test_f1,\n",
        "            'auc': test_auc,\n",
        "            'mcc': test_mcc,\n",
        "            'tp_rate': tp_rate,\n",
        "            'fp_rate': fp_rate,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'tp': tp,\n",
        "            'fp': fp,\n",
        "            'tn': tn,\n",
        "            'fn': fn,\n",
        "        }\n",
        "        return test_metrics, wrong_idx_dict\n",
        "\n",
        "\n",
        "    def fine_tune_model(self, num_epochs=15, base_lr=1e-5):\n",
        "        \"\"\"\n",
        "        Fine-tunes the classification model.\n",
        "\n",
        "        Parameters:\n",
        "        num_epochs (int): Number of epochs to fine-tune (default is 15).\n",
        "        base_lr (float): Base learning rate (default is 1e-5).\n",
        "\n",
        "        Returns:\n",
        "        dict: Training history containing loss and accuracy.\n",
        "        dict: Validation history containing loss, accuracy, f1, auc, and mcc.\n",
        "        dict: Test metrics for TATA sequences containing loss, accuracy, f1, auc, and mcc.\n",
        "        dict: Test metrics for non-TATA sequences containing loss, accuracy, f1, auc, and mcc.\n",
        "        dict: Test metrics for combined sequences containing loss, accuracy, f1, auc, and mcc.\n",
        "        \"\"\"\n",
        "        wrong_idx_dict = defaultdict(list)\n",
        "        model_path = f\"models/bpe/bpe fine tune models/rep/bpe_cls_{self.organism}_model_b{self.batch_size}\"\n",
        "        self.classification_model = RobertaForSequenceClassification.from_pretrained(model_path)\n",
        "        train_history, val_history = None, None\n",
        "\n",
        "        test_tata_history,wrong_idx_dict = self.test_model(wrong_idx_dict, tata_flag='tata')\n",
        "\n",
        "        test_non_tata_history, wrong_idx_dict = self.test_model(wrong_idx_dict, tata_flag='non_tata')\n",
        "\n",
        "        # Combine both test sets\n",
        "        test_combined_history, wrong_idx_dict = self.test_model(wrong_idx_dict, tata_flag='combined')\n",
        "\n",
        "        return train_history, val_history, test_tata_history, test_non_tata_history, test_combined_history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6O9ebwKzkBWS"
      },
      "outputs": [],
      "source": [
        "b_size=16\n",
        "num_epochs=20\n",
        "base_lr=1e-4\n",
        "results_dict = defaultdict(dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzZShW5-1xq0"
      },
      "source": [
        "### Fine tune each organism"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_MxD0CAjkBWT"
      },
      "source": [
        "**celegans**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYlhG5rJkBWT",
        "outputId": "decd9f95-a103-4fdc-d4c5-d8fa7fe958f8",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 1.0352\n",
            "Test Accuracy: 0.7759\n",
            "Test F1 Score: 0.7708\n",
            "Test AUC: 0.8484\n",
            "Test MCC: 0.5523\n",
            "True Positive Rate: 0.7537\n",
            "False Positive Rate: 0.2020\n",
            "Precision: 0.7887\n",
            "Recall: 0.7537\n",
            "True Positives (TP): 153\n",
            "False Positives (FP): 41\n",
            "True Negatives (TN): 162\n",
            "False Negatives (FN): 50\n",
            "\n",
            "non_tata\n",
            "Test Loss: 1.0214\n",
            "Test Accuracy: 0.7729\n",
            "Test F1 Score: 0.7649\n",
            "Test AUC: 0.8561\n",
            "Test MCC: 0.5471\n",
            "True Positive Rate: 0.7390\n",
            "False Positive Rate: 0.1931\n",
            "Precision: 0.7928\n",
            "Recall: 0.7390\n",
            "True Positives (TP): 903\n",
            "False Positives (FP): 236\n",
            "True Negatives (TN): 986\n",
            "False Negatives (FN): 319\n",
            "\n",
            "celegans\n",
            "combined\n",
            "Test Loss: 1.0348\n",
            "Test Accuracy: 0.7733\n",
            "Test F1 Score: 0.7658\n",
            "Test AUC: 0.8552\n",
            "Test MCC: 0.5478\n",
            "True Positive Rate: 0.7411\n",
            "False Positive Rate: 0.1944\n",
            "Precision: 0.7922\n",
            "Recall: 0.7411\n",
            "True Positives (TP): 1056\n",
            "False Positives (FP): 277\n",
            "True Negatives (TN): 1148\n",
            "False Negatives (FN): 369\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'celegans'\n",
        "gamma=0.85\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUqBOH9wkBWT"
      },
      "source": [
        "**gallus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XxOqQCqjkBWT",
        "outputId": "fe678fbe-b983-42c5-ec02-1b316ee2427c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 1.4131\n",
            "Test Accuracy: 0.6556\n",
            "Test F1 Score: 0.5279\n",
            "Test AUC: 0.7379\n",
            "Test MCC: 0.3698\n",
            "True Positive Rate: 0.3852\n",
            "False Positive Rate: 0.0741\n",
            "Precision: 0.8387\n",
            "Recall: 0.3852\n",
            "True Positives (TP): 52\n",
            "False Positives (FP): 10\n",
            "True Negatives (TN): 125\n",
            "False Negatives (FN): 83\n",
            "\n",
            "non_tata\n",
            "Test Loss: 1.3451\n",
            "Test Accuracy: 0.6934\n",
            "Test F1 Score: 0.5863\n",
            "Test AUC: 0.7898\n",
            "Test MCC: 0.4522\n",
            "True Positive Rate: 0.4345\n",
            "False Positive Rate: 0.0477\n",
            "Precision: 0.9011\n",
            "Recall: 0.4345\n",
            "True Positives (TP): 474\n",
            "False Positives (FP): 52\n",
            "True Negatives (TN): 1039\n",
            "False Negatives (FN): 617\n",
            "\n",
            "gallus\n",
            "combined\n",
            "Test Loss: 1.3480\n",
            "Test Accuracy: 0.6892\n",
            "Test F1 Score: 0.5799\n",
            "Test AUC: 0.7837\n",
            "Test MCC: 0.4432\n",
            "True Positive Rate: 0.4290\n",
            "False Positive Rate: 0.0506\n",
            "Precision: 0.8946\n",
            "Recall: 0.4290\n",
            "True Positives (TP): 526\n",
            "False Positives (FP): 62\n",
            "True Negatives (TN): 1164\n",
            "False Negatives (FN): 700\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'gallus'\n",
        "gamma=0.85\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WypTqSLCkBWU"
      },
      "source": [
        "**human**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbASHrmBkBWU",
        "outputId": "1eaf4adb-f68a-4b2b-bb88-84a0a1411006"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 0.6691\n",
            "Test Accuracy: 0.8241\n",
            "Test F1 Score: 0.8376\n",
            "Test AUC: 0.9079\n",
            "Test MCC: 0.6573\n",
            "True Positive Rate: 0.9072\n",
            "False Positive Rate: 0.2590\n",
            "Precision: 0.7779\n",
            "Recall: 0.9072\n",
            "True Positives (TP): 557\n",
            "False Positives (FP): 159\n",
            "True Negatives (TN): 455\n",
            "False Negatives (FN): 57\n",
            "\n",
            "non_tata\n",
            "Test Loss: 0.6980\n",
            "Test Accuracy: 0.8121\n",
            "Test F1 Score: 0.8234\n",
            "Test AUC: 0.8979\n",
            "Test MCC: 0.6295\n",
            "True Positive Rate: 0.8762\n",
            "False Positive Rate: 0.2519\n",
            "Precision: 0.7767\n",
            "Recall: 0.8762\n",
            "True Positives (TP): 4650\n",
            "False Positives (FP): 1337\n",
            "True Negatives (TN): 3970\n",
            "False Negatives (FN): 657\n",
            "\n",
            "human\n",
            "combined\n",
            "Test Loss: 0.6947\n",
            "Test Accuracy: 0.8134\n",
            "Test F1 Score: 0.8249\n",
            "Test AUC: 0.8988\n",
            "Test MCC: 0.6323\n",
            "True Positive Rate: 0.8794\n",
            "False Positive Rate: 0.2527\n",
            "Precision: 0.7768\n",
            "Recall: 0.8794\n",
            "True Positives (TP): 5207\n",
            "False Positives (FP): 1496\n",
            "True Negatives (TN): 4425\n",
            "False Negatives (FN): 714\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'human'\n",
        "gamma=0.8\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlaby6t6kBWU"
      },
      "source": [
        "**melanogaster**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cKZ0yWbkBWV",
        "outputId": "a5c5d205-57d1-4d28-f27f-8b438af329ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 1.0833\n",
            "Test Accuracy: 0.7029\n",
            "Test F1 Score: 0.6737\n",
            "Test AUC: 0.7869\n",
            "Test MCC: 0.4124\n",
            "True Positive Rate: 0.6135\n",
            "False Positive Rate: 0.2077\n",
            "Precision: 0.7471\n",
            "Recall: 0.6135\n",
            "True Positives (TP): 319\n",
            "False Positives (FP): 108\n",
            "True Negatives (TN): 412\n",
            "False Negatives (FN): 201\n",
            "\n",
            "non_tata\n",
            "Test Loss: 0.9153\n",
            "Test Accuracy: 0.7445\n",
            "Test F1 Score: 0.7334\n",
            "Test AUC: 0.8222\n",
            "Test MCC: 0.4907\n",
            "True Positive Rate: 0.7030\n",
            "False Positive Rate: 0.2139\n",
            "Precision: 0.7667\n",
            "Recall: 0.7030\n",
            "True Positives (TP): 2021\n",
            "False Positives (FP): 615\n",
            "True Negatives (TN): 2260\n",
            "False Negatives (FN): 854\n",
            "\n",
            "melanogaster\n",
            "combined\n",
            "Test Loss: 0.9432\n",
            "Test Accuracy: 0.7381\n",
            "Test F1 Score: 0.7247\n",
            "Test AUC: 0.8166\n",
            "Test MCC: 0.4786\n",
            "True Positive Rate: 0.6892\n",
            "False Positive Rate: 0.2130\n",
            "Precision: 0.7640\n",
            "Recall: 0.6892\n",
            "True Positives (TP): 2340\n",
            "False Positives (FP): 723\n",
            "True Negatives (TN): 2672\n",
            "False Negatives (FN): 1055\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'melanogaster'\n",
        "gamma=0.85\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "537WoxeTkBWX"
      },
      "source": [
        "**mulatta**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHogP20CkBWY",
        "outputId": "729a5be9-4288-4c64-b23d-faaa859658d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20, Train Loss: 0.7098, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5188\n",
            "Epoch 2/20, Train Loss: 0.7031, Train Accuracy: 0.5064, Val Loss: 0.7039, Val Accuracy: 0.5000\n",
            "Epoch 3/20, Train Loss: 0.6884, Train Accuracy: 0.5591, Val Loss: 0.6786, Val Accuracy: 0.5960\n",
            "Epoch 4/20, Train Loss: 0.6764, Train Accuracy: 0.5754, Val Loss: 0.6850, Val Accuracy: 0.6230\n",
            "Epoch 5/20, Train Loss: 0.6534, Train Accuracy: 0.6298, Val Loss: 0.6381, Val Accuracy: 0.6411\n",
            "Epoch 6/20, Train Loss: 0.6270, Train Accuracy: 0.6542, Val Loss: 0.6377, Val Accuracy: 0.6418\n",
            "Epoch 7/20, Train Loss: 0.6030, Train Accuracy: 0.6756, Val Loss: 0.6458, Val Accuracy: 0.6322\n",
            "Epoch 8/20, Train Loss: 0.5928, Train Accuracy: 0.6851, Val Loss: 0.6370, Val Accuracy: 0.6381\n",
            "Epoch 9/20, Train Loss: 0.6236, Train Accuracy: 0.6597, Val Loss: 0.6412, Val Accuracy: 0.6414\n",
            "Early stopping triggered\n",
            "tata\n",
            "Test Loss: 0.7753\n",
            "Test Accuracy: 0.5588\n",
            "Test F1 Score: 0.6512\n",
            "Test AUC: 0.6609\n",
            "Test MCC: 0.1387\n",
            "True Positive Rate: 0.8235\n",
            "False Positive Rate: 0.7059\n",
            "Precision: 0.5385\n",
            "Recall: 0.8235\n",
            "True Positives (TP): 14\n",
            "False Positives (FP): 12\n",
            "True Negatives (TN): 5\n",
            "False Negatives (FN): 3\n",
            "\n",
            "non_tata\n",
            "Test Loss: 0.6470\n",
            "Test Accuracy: 0.6324\n",
            "Test F1 Score: 0.6480\n",
            "Test AUC: 0.6763\n",
            "Test MCC: 0.2658\n",
            "True Positive Rate: 0.6768\n",
            "False Positive Rate: 0.4121\n",
            "Precision: 0.6216\n",
            "Recall: 0.6768\n",
            "True Positives (TP): 1043\n",
            "False Positives (FP): 635\n",
            "True Negatives (TN): 906\n",
            "False Negatives (FN): 498\n",
            "\n",
            "combined\n",
            "Test Loss: 0.6472\n",
            "Test Accuracy: 0.6316\n",
            "Test F1 Score: 0.6481\n",
            "Test AUC: 0.6759\n",
            "Test MCC: 0.2643\n",
            "True Positive Rate: 0.6784\n",
            "False Positive Rate: 0.4153\n",
            "Precision: 0.6203\n",
            "Recall: 0.6784\n",
            "True Positives (TP): 1057\n",
            "False Positives (FP): 647\n",
            "True Negatives (TN): 911\n",
            "False Negatives (FN): 501\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'mulatta'\n",
        "gamma=0.85\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VmFVto6kBWY"
      },
      "source": [
        "**musculus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mOrDLV1kBWY",
        "outputId": "6a956d09-a83d-42a8-9c8d-251956256e2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 1.1258\n",
            "Test Accuracy: 0.8082\n",
            "Test F1 Score: 0.8124\n",
            "Test AUC: 0.8845\n",
            "Test MCC: 0.6169\n",
            "True Positive Rate: 0.8308\n",
            "False Positive Rate: 0.2145\n",
            "Precision: 0.7948\n",
            "Recall: 0.8308\n",
            "True Positives (TP): 550\n",
            "False Positives (FP): 142\n",
            "True Negatives (TN): 520\n",
            "False Negatives (FN): 112\n",
            "\n",
            "non_tata\n",
            "Test Loss: 1.1041\n",
            "Test Accuracy: 0.8157\n",
            "Test F1 Score: 0.8156\n",
            "Test AUC: 0.8886\n",
            "Test MCC: 0.6314\n",
            "True Positive Rate: 0.8155\n",
            "False Positive Rate: 0.1841\n",
            "Precision: 0.8158\n",
            "Recall: 0.8155\n",
            "True Positives (TP): 3557\n",
            "False Positives (FP): 803\n",
            "True Negatives (TN): 3559\n",
            "False Negatives (FN): 805\n",
            "\n",
            "musculus\n",
            "combined\n",
            "Test Loss: 1.1072\n",
            "Test Accuracy: 0.8147\n",
            "Test F1 Score: 0.8152\n",
            "Test AUC: 0.8881\n",
            "Test MCC: 0.6294\n",
            "True Positive Rate: 0.8175\n",
            "False Positive Rate: 0.1881\n",
            "Precision: 0.8129\n",
            "Recall: 0.8175\n",
            "True Positives (TP): 4107\n",
            "False Positives (FP): 945\n",
            "True Negatives (TN): 4079\n",
            "False Negatives (FN): 917\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'musculus'\n",
        "# gamma=0.75\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAnZyvJ_kBWZ"
      },
      "source": [
        "**norvegicus**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCV7oVEDkBWZ",
        "outputId": "f4eecf41-49b3-4642-c541-80b410e37d21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 0.8881\n",
            "Test Accuracy: 0.7607\n",
            "Test F1 Score: 0.7797\n",
            "Test AUC: 0.8337\n",
            "Test MCC: 0.5293\n",
            "True Positive Rate: 0.8466\n",
            "False Positive Rate: 0.3252\n",
            "Precision: 0.7225\n",
            "Recall: 0.8466\n",
            "True Positives (TP): 138\n",
            "False Positives (FP): 53\n",
            "True Negatives (TN): 110\n",
            "False Negatives (FN): 25\n",
            "\n",
            "non_tata\n",
            "Test Loss: 0.9191\n",
            "Test Accuracy: 0.7391\n",
            "Test F1 Score: 0.7574\n",
            "Test AUC: 0.8202\n",
            "Test MCC: 0.4837\n",
            "True Positive Rate: 0.8146\n",
            "False Positive Rate: 0.3364\n",
            "Precision: 0.7077\n",
            "Recall: 0.8146\n",
            "True Positives (TP): 1775\n",
            "False Positives (FP): 733\n",
            "True Negatives (TN): 1446\n",
            "False Negatives (FN): 404\n",
            "\n",
            "norvegicus\n",
            "combined\n",
            "Test Loss: 0.9142\n",
            "Test Accuracy: 0.7406\n",
            "Test F1 Score: 0.7590\n",
            "Test AUC: 0.8211\n",
            "Test MCC: 0.4869\n",
            "True Positive Rate: 0.8168\n",
            "False Positive Rate: 0.3356\n",
            "Precision: 0.7088\n",
            "Recall: 0.8168\n",
            "True Positives (TP): 1913\n",
            "False Positives (FP): 786\n",
            "True Negatives (TN): 1556\n",
            "False Negatives (FN): 429\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'norvegicus'\n",
        "gamma=0.85\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dj4q7IrgkBWa"
      },
      "source": [
        "**rerio**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQavPHfNkBWa",
        "outputId": "5d4754f8-e60c-4978-bef2-9ce069baaf4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tata\n",
            "Test Loss: 1.0304\n",
            "Test Accuracy: 0.7026\n",
            "Test F1 Score: 0.7165\n",
            "Test AUC: 0.7831\n",
            "Test MCC: 0.4071\n",
            "True Positive Rate: 0.7518\n",
            "False Positive Rate: 0.3466\n",
            "Precision: 0.6844\n",
            "Recall: 0.7518\n",
            "True Positives (TP): 321\n",
            "False Positives (FP): 148\n",
            "True Negatives (TN): 279\n",
            "False Negatives (FN): 106\n",
            "\n",
            "non_tata\n",
            "Test Loss: 0.9994\n",
            "Test Accuracy: 0.7215\n",
            "Test F1 Score: 0.7358\n",
            "Test AUC: 0.7909\n",
            "Test MCC: 0.4456\n",
            "True Positive Rate: 0.7756\n",
            "False Positive Rate: 0.3326\n",
            "Precision: 0.6999\n",
            "Recall: 0.7756\n",
            "True Positives (TP): 1334\n",
            "False Positives (FP): 572\n",
            "True Negatives (TN): 1148\n",
            "False Negatives (FN): 386\n",
            "\n",
            "rerio\n",
            "combined\n",
            "Test Loss: 1.0042\n",
            "Test Accuracy: 0.7177\n",
            "Test F1 Score: 0.7320\n",
            "Test AUC: 0.7893\n",
            "Test MCC: 0.4380\n",
            "True Positive Rate: 0.7708\n",
            "False Positive Rate: 0.3354\n",
            "Precision: 0.6968\n",
            "Recall: 0.7708\n",
            "True Positives (TP): 1655\n",
            "False Positives (FP): 720\n",
            "True Negatives (TN): 1427\n",
            "False Negatives (FN): 492\n",
            "\n"
          ]
        }
      ],
      "source": [
        "organism = 'rerio'\n",
        "gamma=0.85\n",
        "\n",
        "cls_model = ClassificationModelBPE(train, val, test_tata, test_non_tata, organism=organism, b_size=b_size)\n",
        "train_history, val_history, test_tata_history, test_non_tata_history, test_all_data_history = cls_model.fine_tune_model(num_epochs=num_epochs, base_lr=base_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_RuzZdkDDjp"
      },
      "source": [
        "# SHAP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KScVS5JEDDjq"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "psk17-EyDDjr"
      },
      "outputs": [],
      "source": [
        "train_tata = pd.read_csv(\"data_exp1/train_tata_met_2.csv\", index_col = False)\n",
        "val_tata = pd.read_csv(\"data_exp1/val_tata_met_2.csv\", index_col = False)\n",
        "test_tata = pd.read_csv('data_exp1/test_tata_met_2.csv', index_col = False)\n",
        "\n",
        "train_non_tata = pd.read_csv('data_exp1/train_non_tata_met_2.csv', index_col = False)\n",
        "val_non_tata = pd.read_csv('data_exp1/val_non_tata_met_2.csv', index_col = False)\n",
        "test_non_tata = pd.read_csv('data_exp1/test_non_tata_met_2.csv', index_col = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GX-D0g85DDjr"
      },
      "outputs": [],
      "source": [
        "tokenizer_dir = 'models/bpe_tokenizer'\n",
        "\n",
        "tokenizer = RobertaTokenizerFast.from_pretrained(tokenizer_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hkYni3PDDjs"
      },
      "outputs": [],
      "source": [
        "non_tata_test_seq = test_non_tata[test_non_tata['organism'] == 'human']['seq'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QqfknSzcDDjt"
      },
      "outputs": [],
      "source": [
        "test_tata_seq = test_tata[test_tata['organism'] == 'human']['seq'].tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "us2g0kmiDDjt"
      },
      "outputs": [],
      "source": [
        "test_all = non_tata_test_seq + test_tata_seq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NI3PhBQZDDju",
        "outputId": "3691ca37-e2e3-4785-bf72-109157b0bea1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        }
      ],
      "source": [
        "test_encodings_all = tokenizer(test_all, truncation=True, padding=True, return_tensors='pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8uvNMEUDDjv"
      },
      "outputs": [],
      "source": [
        "# Move inputs and masks to device\n",
        "input_ids = test_encodings_all['input_ids'].to(device)\n",
        "attention_mask = test_encodings_all['attention_mask'].to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9YDKwrsDDjw"
      },
      "outputs": [],
      "source": [
        "test_encodings_tokens_subset = test_encodings_all['input_ids'][:10000]\n",
        "# test_encodings_tokens_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jjVhuVNYDDjw"
      },
      "outputs": [],
      "source": [
        "masker = shap.maskers.Partition(np.array(test_encodings_tokens_subset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SkySYb9DDjx"
      },
      "outputs": [],
      "source": [
        "def plot_shap_values(shap_dict, type=\"Global\"):\n",
        "  toekns = shap_dict.keys()\n",
        "  shap_values_ls = shap_dict.values()\n",
        "\n",
        "  # Determine the color for each bar based on positive or negative value\n",
        "  colors = ['green' if value >= 0 else 'red' for value in shap_values_ls]\n",
        "\n",
        "  # Create a bar plott with colors based on positive or negative values\n",
        "  plt.figure(figsize=(25, 6))\n",
        "  plt.bar(toekns, shap_values_ls, width=0.5, color=colors)\n",
        "\n",
        "  # Add title and labels to the plot\n",
        "  plt.title(f'{type} SHAP Values per Token')\n",
        "  plt.xlabel('Token')\n",
        "  plt.ylabel('SHAP Value')\n",
        "  plt.tight_layout()\n",
        "  plt.xticks(rotation = 90)\n",
        "\n",
        "  # Show the plot\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3jzCfChCDDjy"
      },
      "outputs": [],
      "source": [
        "def model_predictions_for_shap(tokenized_data):\n",
        "    model.eval()  # Ensure the model is in evaluation mode\n",
        "\n",
        "    # Check if tokenized_data is already a tensor, then move it to the device\n",
        "    if isinstance(tokenized_data, torch.Tensor):\n",
        "        tensored_data = tokenized_data.to(device)\n",
        "    else:\n",
        "        # If tokenized_data is not a tensor (e.g., a list or numpy array),\n",
        "        # convert it efficiently to a tensor and then move to the device.\n",
        "        tensored_data = torch.as_tensor(tokenized_data, device=device)\n",
        "\n",
        "    with torch.no_grad():  # Context manager that disables gradient calculation\n",
        "        logits = model(tensored_data).logits\n",
        "        probabilities = F.softmax(logits, dim=1)  # Compute probabilities\n",
        "\n",
        "    return probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lVsBRhwZDDjy",
        "outputId": "fea56eb5-3571-49f6-c535-6ea6a62cd614"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_dir = 'models/bpe fine tune models/method2/bpe_cls_human_model_b16'\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwbkyEIjDDjz",
        "outputId": "74989d92-fae7-41cd-8d58-1c9380f9b0ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-5): 6 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1_bKkM5DDj0"
      },
      "outputs": [],
      "source": [
        "# Tokenize your test sequences\n",
        "test_encodings_all = {key: value.to(device) for key, value in test_encodings_all.items()}\n",
        "input_ids = test_encodings_all['input_ids']\n",
        "attention_mask = test_encodings_all['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GcwqjQc_DDj1"
      },
      "outputs": [],
      "source": [
        "# Subset of tokens for SHAP analysis\n",
        "test_encodings_tokens_subset = input_ids[:10000].cpu().numpy()  # Move to CPU and convert to numpy array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NsyVu5D7DDj2"
      },
      "outputs": [],
      "source": [
        "# Define SHAP masker\n",
        "masker = shap.maskers.Partition(test_encodings_tokens_subset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XEZUK4YPDDj2"
      },
      "outputs": [],
      "source": [
        "explainer = shap.PartitionExplainer(model_predictions_for_shap, masker)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju-ovsrADDj3",
        "outputId": "5afb7e4f-f2f3-46e0-870c-b2643024baeb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
            "PartitionExplainer explainer: 10001it [5:22:42,  1.94s/it]                            \n"
          ]
        }
      ],
      "source": [
        "shap_values = explainer(np.array(test_encodings_tokens_subset), max_evals=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "soX0nmWeDDj4"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('models/SHAP/shap_bpe_human/shap_values_10000_met2.pkl', 'wb') as file:\n",
        "    pickle.dump(shap_values, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xvMDItiXDDj4",
        "outputId": "1db9e934-94f7-45ce-9c9e-b4b1cfb1baba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique features: 30000\n"
          ]
        }
      ],
      "source": [
        "# Accessing all unique features and tokens\n",
        "unique_features = list(tokenizer.get_vocab().keys())\n",
        "unique_tokens = list(tokenizer.get_vocab().values())\n",
        "tokens_and_features_dict = dict(zip(unique_tokens, unique_features))\n",
        "\n",
        "print(f\"Number of unique features: {len(unique_features)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}